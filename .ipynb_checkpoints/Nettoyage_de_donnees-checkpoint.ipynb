{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et nettoyage des données en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce tutoriel, nous allons receuillir les avis des internautes sur Facebook et tweetter sur la pannes facebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des datasets des réseaux sociaux sur la panne de facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_json('facebookdown1_1.json', encoding=\"utf-8-sig\")\n",
    "data2 = pd.read_json('facebookdown1_2.json', encoding='utf-8-sig')\n",
    "data3 = pd.read_json('tweets.json', encoding='utf-8-sig')\n",
    "data4 = pd.read_json('tweets2.json', encoding='utf-8-sig')\n",
    "data5 = pd.read_json('france24.json', encoding='utf-8-sig')\n",
    "data6 = pd.read_json('zdnet.json', encoding='utf-8-sig')\n",
    "data7 = pd.read_json('downdetector.json', encoding='utf-8-sig')\n",
    "data8 = pd.read_json('bbc.json', encoding='utf-8-sig')\n",
    "data9 = pd.read_json('datacenter_magazine.json', encoding='utf-8-sig')\n",
    "data10 = pd.read_json('frandroid.json', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout des liens vers les réseaux sociaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['reseaux_social'] = np.vectorize( lambda x: x )('Facebook')\n",
    "data1['lien'] = np.vectorize( lambda x: x )('https://www.facebook.com/hashtag/facebookdown')\n",
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['reseaux_social'] = np.vectorize( lambda x: x )('Facebook')\n",
    "data2['lien'] = np.vectorize( lambda x: x )('https://www.facebook.com/hashtag/pannefacebook')\n",
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['reseaux_social'] = np.vectorize( lambda x: x )('Tweetter')\n",
    "data3['lien'] = np.vectorize( lambda x: x )('https://twitter.com/kevinlimonier/status/1445130431704281092')\n",
    "data3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['reseaux_social'] = np.vectorize( lambda x: x )('Tweetter')\n",
    "data4['lien'] = np.vectorize( lambda x: x )('https://twitter.com/search?q=piratage%20facebook&src=typed_query&f=top')\n",
    "data4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5['reseaux_social'] = np.vectorize( lambda x: x )('Tweetter')\n",
    "data5['lien'] = np.vectorize( lambda x: x )('https://twitter.com/search?q=piratage%20facebook&src=typed_query&f=top')\n",
    "data5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5['reseaux_social'] = np.vectorize( lambda x: x )('France24')\n",
    "data5['lien'] = np.vectorize( lambda x: x )('https://www.france24.com/fr/%C3%A9co-tech/20211004-panne-mondiale-pour-facebook-instagram-whatsapp-et-messenger')\n",
    "data5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6['reseaux_social'] = np.vectorize( lambda x: x )('Zdnet')\n",
    "data6['lien'] = np.vectorize( lambda x: x )('https://www.zdnet.fr/actualites/voici-ce-qui-a-provoque-la-panne-de-facebook-et-instagram-et-whatsapp-39930251.htm')\n",
    "data6.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7['reseaux_social'] = np.vectorize( lambda x: x )('Downdetector')\n",
    "data7['lien'] = np.vectorize( lambda x: x )('https://downdetector.fr/statut/facebook/')\n",
    "data7.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8['reseaux_social'] = np.vectorize( lambda x: x )('BBC')\n",
    "data8['lien'] = np.vectorize( lambda x: x )('https://www.bbc.com/afrique/monde-58816128')\n",
    "data8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data9['reseaux_social'] = np.vectorize( lambda x: x )('Datacenter_magazine')\n",
    "data9['lien'] = np.vectorize( lambda x: x )('https://datacenter-magazine.fr/panne-facebook-une-cascade-de-consequences/')\n",
    "data9.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data10['reseaux_social'] = np.vectorize( lambda x: x )('Frandroid')\n",
    "data10['lien'] = np.vectorize( lambda x: x )('https://www.frandroid.com/android/1085647_voici-ce-qui-a-cause-la-panne-massive-de-facebook-instagram-et-whatsapp#:~:text=Facebook%20indique%20ainsi%20que%20sa,diff%C3%A9rents%20serveurs%20du%20groupe%20am%C3%A9ricain.')\n",
    "data10.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification de la taille de chaque dataset de chacun des réseaux sociaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'taille data1: {}\\ntaille data2: {}\\ntaille data3: {}\\ntaille data4: {}\\ntaille: data5: {}\\ntaille data6: {}\\ntaille data7: {}\\ntaille data8: {}\\ntaille data9: {}\\ntaille data10 {}'    .format(\n",
    "        len(data1), \n",
    "        len(data2), \n",
    "        len(data3),\n",
    "        len(data4),\n",
    "        len(data5),\n",
    "        len(data6),\n",
    "        len(data7),\n",
    "        len(data8),\n",
    "        len(data9),\n",
    "        len(data10)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion des datasets en un seul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        data1,\n",
    "        data2, \n",
    "        data3, \n",
    "        data4, \n",
    "        data5, \n",
    "        data6,\n",
    "        data7, \n",
    "        data8, \n",
    "        data9, \n",
    "        data10\n",
    "    ], \n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification de la taille de notre dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('taille df: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des doublons et retour chario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df['avis'].drop_duplicates()\n",
    "    df['avis'].str.rstrip()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taille final après suppression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des caractères spéciaux et retours chario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['avis'].str.strip()\n",
    "# df['avis'].str.rstrip()\n",
    "df['avis'][0] = df['avis'][0][321:]\n",
    "# for i in range(0, len(df['avis'])):\n",
    "#     try:\n",
    "#         df['avis'][i] = df['avis'][i].replace('\\n', '')\n",
    "#         df['avis'][i] = df['avis'][i].replace('\\\\', '')\n",
    "#         df['avis'][i] = df['avis'][i].replace('\\n\\n', '')\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "clean_data = [i.replace('\\n', '') for i in df['avis']] # supprimer retour à la ligne\n",
    "clean_data = [i.replace('\\\\', '') for i in clean_data] # supprimer \\\n",
    "clean_data = [i.replace('/', '') for i in clean_data] # supprimer /\n",
    "clean_data = [i.replace('\\xa0»\\xa0?', 'été') for i in clean_data] # remplacer \\xa0»\\xa0? par été\n",
    "# clean_data = [ fr'{text}' for text in clean_data]\n",
    "\n",
    "for i, phrase in enumerate(clean_data):\n",
    "    if ' ' not in phrase:\n",
    "        clean_data.pop(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de notre dataset nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = pd.DataFrame(clean_data)\n",
    "dataset_final.to_csv('analyse_sentiment_facebook.csv', index_label=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testons note dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('analyse_sentiment_facebook.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appliquons quelques analyses statiques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
